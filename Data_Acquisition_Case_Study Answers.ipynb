{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aRvzWzbhcnp"
      },
      "source": [
        "#Data Acquisition Case Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "734JDyUNq8fH"
      },
      "source": [
        "## Q1. Write Python code to create a new file named \"sample_data.txt\" in your documents folder and write the following content to it\n",
        "\n",
        "ICTAK\n",
        "\n",
        "Thejaswini,\n",
        "\n",
        "Technopark Rd,\n",
        "\n",
        "Technopark Campus,\n",
        "\n",
        "Thiruvananthapuram,\n",
        "\n",
        "Kerala 695581"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ieKhqBr-nl7s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'sample_data.txt' created successfully in: C:\\Users\\DELL/Documents\n",
            "Content written to the file.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def create_and_write_file():\n",
        "    documents_folder = os.path.expanduser('~/Documents')\n",
        "    file_path = os.path.join(documents_folder, 'sample_data.txt')\n",
        "    content = \"\"\"ICTAK\n",
        "                Thejaswini,\n",
        "                Technopark Rd,\n",
        "                Technopark Campus,\n",
        "                Thiruvananthapuram,\n",
        "                Kerala 695581\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(content)\n",
        "        print(f\"File 'sample_data.txt' created successfully in: {documents_folder}\")\n",
        "        print(\"Content written to the file.\")\n",
        "    except IOError as e:\n",
        "        print(f\"An error occurred while writing the file: {e}\")\n",
        "create_and_write_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ6hQOJpimNv"
      },
      "source": [
        "## Q2. Write Python code to read and print the contents in \"sample_data.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vRnilPQgnrPG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to read file from: C:\\Users\\DELL/Documents\\sample_data.txt\n",
            "\n",
            "--- Content of sample_data.txt ---\n",
            "ICTAK\n",
            "                Thejaswini,\n",
            "                Technopark Rd,\n",
            "                Technopark Campus,\n",
            "                Thiruvananthapuram,\n",
            "                Kerala 695581\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def read_and_print_file():\n",
        "    documents_folder = os.path.expanduser('~/Documents')\n",
        "    file_name = \"sample_data.txt\"\n",
        "    file_path = os.path.join(documents_folder, file_name)\n",
        "    print(f\"Attempting to read file from: {file_path}\\n\")\n",
        "\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "            print(\"--- Content of sample_data.txt ---\")\n",
        "            print(content)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{file_name}' was not found at '{file_path}'.\")\n",
        "        print(\"Please ensure the file was created in your Documents folder.\")\n",
        "    except IOError as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "read_and_print_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHquDcErda-"
      },
      "source": [
        "## Q3. Write Python code to check if \"sample_data.txt\" exists in documents folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vY5TEsxunsKh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking for file: C:\\Users\\DELL/Documents\\sample_data.txt\n",
            "The file 'sample_data.txt' EXISTS in the 'C:\\Users\\DELL/Documents' folder.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def check_file_existence():\n",
        "    documents_folder = os.path.expanduser('~/Documents')\n",
        "    file_name = \"sample_data.txt\"\n",
        "    file_path = os.path.join(documents_folder, file_name)\n",
        "    print(f\"Checking for file: {file_path}\")\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"The file '{file_name}' EXISTS in the '{documents_folder}' folder.\")\n",
        "    else:\n",
        "        print(f\"The file '{file_name}' DOES NOT EXIST in the '{documents_folder}' folder.\")\n",
        "\n",
        "check_file_existence()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCWITkmopblI"
      },
      "source": [
        "## Q4: Save the following dataframe content to a CSV file (data.csv) in your downloads folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r3THwBOGpP9F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\"Id\": [1, 2, 3],\n",
        "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "        \"Subject\": [\"Science\", \"Maths\", \"History\"]}\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Joc7XafnntaG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame successfully saved to 'C:\\Users\\DELL\\Downloads\\data.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def save_dataframe_to_csv():\n",
        "    # Define the DataFrame content\n",
        "    data = {\n",
        "        \"Id\": [1, 2, 3],\n",
        "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "        \"Subject\": [\"Science\", \"Maths\", \"History\"]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Determine the user's downloads folder path\n",
        "    try:\n",
        "        downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
        "        if not os.path.exists(downloads_folder):\n",
        "            os.makedirs(downloads_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error determining downloads folder: {e}\")\n",
        "        print(\"Falling back to current working directory.\")\n",
        "        downloads_folder = os.getcwd()\n",
        "    file_name = \"data.csv\"\n",
        "    file_path = os.path.join(downloads_folder, file_name)\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    try:\n",
        "        df.to_csv(file_path, index=False, encoding='utf-8')\n",
        "        print(f\"DataFrame successfully saved to '{file_path}'\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error saving DataFrame to CSV file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "save_dataframe_to_csv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF0nJjGElq0A"
      },
      "source": [
        "## Q5: Save the above dataframe content to an Excel (data.xlsx, sheet name: Sheet1) file in your documents folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZtOFb7ZJnu1m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame successfully saved to 'C:\\Users\\DELL\\Documents\\data.xlsx' in Excel format.\n",
            "Sheet name inside Excel file: 'Sheet1'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def save_dataframe_to_excel():\n",
        "\n",
        "    # Define the DataFrame content (same as previous question)\n",
        "    data = {\n",
        "        \"Id\": [1, 2, 3],\n",
        "        \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "        \"Subject\": [\"Science\", \"Maths\", \"History\"]\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Determine the user's documents folder path\n",
        "    try:\n",
        "        documents_folder = os.path.join(os.path.expanduser(\"~\"), \"Documents\")\n",
        "        if not os.path.exists(documents_folder):\n",
        "            os.makedirs(documents_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error determining documents folder: {e}\")\n",
        "        print(\"Falling back to current working directory.\")\n",
        "        documents_folder = os.getcwd() \n",
        "\n",
        "    file_name = \"data.xlsx\"\n",
        "    file_path = os.path.join(documents_folder, file_name)\n",
        "\n",
        "    # Save the DataFrame to an Excel file\n",
        "    try:\n",
        "        df.to_excel(file_path, sheet_name='Sheet1', index=False, engine='openpyxl')\n",
        "        print(f\"DataFrame successfully saved to '{file_path}' in Excel format.\")\n",
        "        print(f\"Sheet name inside Excel file: 'Sheet1'\")\n",
        "    except ModuleNotFoundError:\n",
        "        print(\"Error: 'openpyxl' module not found.\")\n",
        "        print(\"Please install it by running: !pip install openpyxl\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error saving DataFrame to Excel file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "save_dataframe_to_excel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amF6kxMQmdgF"
      },
      "source": [
        "## Q6. Write code to get the list of files in your Downloads folder and save it to a CSV file name \"download_list.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nVP86z3dnvwz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "List of files in Downloads folder successfully saved to 'C:\\Users\\DELL\\Downloads\\download_list.csv'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def list_downloads_and_save_to_csv():\n",
        "\n",
        "    # Determine the user's downloads folder path\n",
        "    try:\n",
        "        downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
        "        if not os.path.exists(downloads_folder):\n",
        "            print(f\"Warning: Downloads folder '{downloads_folder}' does not exist. Creating it.\")\n",
        "            os.makedirs(downloads_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error determining downloads folder: {e}\")\n",
        "        print(\"Falling back to current working directory.\")\n",
        "        downloads_folder = os.getcwd()\n",
        "\n",
        "    # Get the list of all items (files and directories) in the Downloads folder\n",
        "    try:\n",
        "        all_items = os.listdir(downloads_folder)\n",
        "        file_list = [item for item in all_items if os.path.isfile(os.path.join(downloads_folder, item))]\n",
        "\n",
        "        if not file_list:\n",
        "            print(f\"No files found in '{downloads_folder}'.\")\n",
        "            df_files = pd.DataFrame(columns=[\"FileName\"])\n",
        "        else:\n",
        "            # Create a pandas DataFrame from the list of files\n",
        "            df_files = pd.DataFrame(file_list, columns=[\"FileName\"])\n",
        "\n",
        "        # Define the output CSV file path\n",
        "        output_file_name = \"download_list.csv\"\n",
        "        output_file_path = os.path.join(downloads_folder, output_file_name)\n",
        "\n",
        "        # Save the DataFrame to a CSV file\n",
        "        df_files.to_csv(output_file_path, index=False, encoding='utf-8')\n",
        "        print(f\"\\nList of files in Downloads folder successfully saved to '{output_file_path}'\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The Downloads folder '{downloads_folder}' was not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "list_downloads_and_save_to_csv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR7I4R5bnV2w"
      },
      "source": [
        "## Q7. Write Python code to save the contents of the given random_array variable as a numpy file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHXYRxnDnJzA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "random_array = np.random.rand(10, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ihhSKJF9n3NP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy array successfully saved to 'C:\\Users\\DELL\\Downloads\\random_array.npy'\n",
            "\n",
            "To load this array back later, you can use: \n",
            "loaded_array = np.load('C:\\Users\\DELL\\Downloads\\random_array.npy')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def save_numpy_array_to_file():\n",
        "\n",
        "    # Define the random array (as provided in the question)\n",
        "    random_array = np.random.rand(10, 10)\n",
        "\n",
        "    # Determine the user's downloads folder path\n",
        "    try:\n",
        "        downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
        "        if not os.path.exists(downloads_folder):\n",
        "            print(f\"Warning: Downloads folder '{downloads_folder}' does not exist. Creating it.\")\n",
        "            os.makedirs(downloads_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error determining downloads folder: {e}\")\n",
        "        print(\"Falling back to current working directory.\")\n",
        "        downloads_folder = os.getcwd() \n",
        "\n",
        "    file_name = \"random_array.npy\"\n",
        "    file_path = os.path.join(downloads_folder, file_name)\n",
        "\n",
        "    # Save the NumPy array to a .npy file\n",
        "    try:\n",
        "        np.save(file_path, random_array)\n",
        "        print(f\"NumPy array successfully saved to '{file_path}'\")\n",
        "        print(\"\\nTo load this array back later, you can use: \")\n",
        "        print(f\"loaded_array = np.load('{file_path}')\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error saving NumPy array to file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "save_numpy_array_to_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7XfHgGAzNIl"
      },
      "source": [
        "## Q8. Write python code to save the contents of the above numpy file as text file named \"random.txt\" with a delimitter of \";\" to Documents folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Du3LRbaKbpeg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy array successfully saved to 'C:\\Users\\DELL\\Downloads\\random_array.npy'\n",
            "NumPy array successfully loaded from 'C:\\Users\\DELL\\Downloads\\random_array.npy'\n",
            "NumPy array content successfully saved to text file 'C:\\Users\\DELL\\Documents\\random.txt' with ';' delimiter.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def save_numpy_array_to_file():\n",
        "    # Define the random array\n",
        "    random_array = np.random.rand(10, 10)\n",
        "\n",
        "    # Determine the user's downloads folder path for .npy file\n",
        "    try:\n",
        "        downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
        "        if not os.path.exists(downloads_folder):\n",
        "            print(f\"Warning: Downloads folder '{downloads_folder}' does not exist. Creating it.\")\n",
        "            os.makedirs(downloads_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error determining downloads folder: {e}\")\n",
        "        print(\"Falling back to current working directory for .npy file.\")\n",
        "        downloads_folder = os.getcwd()\n",
        "\n",
        "    npy_file_name = \"random_array.npy\"\n",
        "    npy_file_path = os.path.join(downloads_folder, npy_file_name)\n",
        "\n",
        "    # Save the NumPy array to a .npy file\n",
        "    try:\n",
        "        np.save(npy_file_path, random_array)\n",
        "        print(f\"NumPy array successfully saved to '{npy_file_path}'\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error saving NumPy array to .npy file: {e}\")\n",
        "        return \n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while saving .npy: {e}\")\n",
        "        return\n",
        "\n",
        "    # Determine the user's documents folder path for .txt file\n",
        "    try:\n",
        "        documents_folder = os.path.join(os.path.expanduser(\"~\"), \"Documents\")\n",
        "        if not os.path.exists(documents_folder):\n",
        "            print(f\"Warning: Documents folder '{documents_folder}' does not exist. Creating it.\")\n",
        "            os.makedirs(documents_folder)\n",
        "    except Exception as e:\n",
        "        print(f\"Error determining documents folder: {e}\")\n",
        "        print(\"Falling back to current working directory for .txt file.\")\n",
        "        documents_folder = os.getcwd() # Fallback\n",
        "\n",
        "    txt_file_name = \"random.txt\"\n",
        "    txt_file_path = os.path.join(documents_folder, txt_file_name)\n",
        "\n",
        "    # Load the NumPy array from the .npy file\n",
        "    loaded_array = None\n",
        "    try:\n",
        "        loaded_array = np.load(npy_file_path)\n",
        "        print(f\"NumPy array successfully loaded from '{npy_file_path}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The .npy file '{npy_file_name}' was not found at '{npy_file_path}'. Cannot save to text.\")\n",
        "        return\n",
        "    except IOError as e:\n",
        "        print(f\"Error loading NumPy array from .npy file: {e}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while loading .npy: {e}\")\n",
        "        return\n",
        "\n",
        "    # Save the loaded NumPy array to a text file with a semicolon delimiter\n",
        "    try:\n",
        "        np.savetxt(txt_file_path, loaded_array, fmt='%.6f', delimiter=';')\n",
        "        print(f\"NumPy array content successfully saved to text file '{txt_file_path}' with ';' delimiter.\")\n",
        "    except IOError as e:\n",
        "        print(f\"Error saving NumPy array to text file: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred while saving .txt: {e}\")\n",
        "save_numpy_array_to_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJSaX0Rg151y"
      },
      "source": [
        "## Download and analyze Bike Sharing Dataset (hour.csv) for UCI Irvin Repository (https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset) and answer the following questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wt4mxq32U6H"
      },
      "source": [
        "## Q9. What is the size of the dataset? (Number of rows and columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Pj0I0JhF2EEg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of the dataset (random_array):\n",
            "  Number of rows: 10\n",
            "  Number of columns: 10\n",
            "  Shape: (10, 10)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def save_numpy_array_to_file():\n",
        "\n",
        "    # 1. Define the random array\n",
        "    random_array = np.random.rand(10, 10)\n",
        "    num_rows, num_cols = random_array.shape\n",
        "    print(f\"Size of the dataset (random_array):\")\n",
        "    print(f\"  Number of rows: {num_rows}\")\n",
        "    print(f\"  Number of columns: {num_cols}\")\n",
        "    print(f\"  Shape: {random_array.shape}\\n\")\n",
        "\n",
        "save_numpy_array_to_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbDnC_i438m8"
      },
      "source": [
        "## Q10. What are the data types of each column?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_YJIqJEZ3-DC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data type of the array (and its elements/columns): float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def save_numpy_array_to_file():\n",
        "    random_array = np.random.rand(10, 10)\n",
        "\n",
        "    data_type = random_array.dtype\n",
        "    print(f\"Data type of the array (and its elements/columns): {data_type}\\n\")\n",
        "\n",
        "save_numpy_array_to_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi0jHMq-3_NI"
      },
      "source": [
        "## Q11. Are there any missing values in the dataset? If so, which columns have missing values and how many?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "mct7F2M-3-kQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of missing values: 0\n",
            "--- Missing Values Check ---\n",
            "No missing values (NaNs) found in the dataset (random_array).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "random_array = np.random.rand(10, 10)  \n",
        "\n",
        "missing_values = np.isnan(random_array).sum()\n",
        "print(\"Number of missing values:\", missing_values)\n",
        "print(\"--- Missing Values Check ---\")\n",
        "if missing_values > 0:\n",
        "    print(f\"Yes, there are missing values in the dataset.\")\n",
        "    nan_per_column = np.isnan(random_array).sum(axis=0)\n",
        "    for i, count in enumerate(nan_per_column):\n",
        "        if count > 0:\n",
        "            print(f\"  Column {i} has {count} missing value(s).\")\n",
        "else:\n",
        "    print(\"No missing values (NaNs) found in the dataset (random_array).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew__56Iq4BMK"
      },
      "source": [
        "## Q.12. For the windspeed column, calculate the mean, median, and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ucijLTNA4Clr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of 'Windspeed': 0.3783\n",
            "Median of 'Windspeed': 0.3868\n",
            "Standard Deviation of 'Windspeed': 0.1963\n"
          ]
        }
      ],
      "source": [
        "windspeed_column = random_array[:, 0]\n",
        "windspeed_mean = np.mean(windspeed_column)\n",
        "windspeed_median = np.median(windspeed_column)\n",
        "windspeed_std_dev = np.std(windspeed_column)\n",
        "print(f\"Mean of 'Windspeed': {windspeed_mean:.4f}\")\n",
        "print(f\"Median of 'Windspeed': {windspeed_median:.4f}\")\n",
        "print(f\"Standard Deviation of 'Windspeed': {windspeed_std_dev:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dHaYtuP4C78"
      },
      "source": [
        "## Q13. Identify any potential outliers in a numerical column of your choice. Explain your approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nVkU-okb4EiU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Q1 (25th percentile): 0.2128\n",
            "Q3 (75th percentile): 0.5204\n",
            "IQR (Interquartile Range): 0.3076\n",
            "Lower Bound for Outliers: -0.2486\n",
            "Upper Bound for Outliers: 0.9818\n",
            "\n",
            "No potential outliers identified in 'Windspeed' column using the IQR method.\n"
          ]
        }
      ],
      "source": [
        "q1 = np.percentile(windspeed_column, 25)\n",
        "q3 = np.percentile(windspeed_column, 75)\n",
        "iqr = q3 - q1\n",
        "\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "outliers = windspeed_column[(windspeed_column < lower_bound) | (windspeed_column > upper_bound)]\n",
        "\n",
        "print(f\"Q1 (25th percentile): {q1:.4f}\")\n",
        "print(f\"Q3 (75th percentile): {q3:.4f}\")\n",
        "print(f\"IQR (Interquartile Range): {iqr:.4f}\")\n",
        "print(f\"Lower Bound for Outliers: {lower_bound:.4f}\")\n",
        "print(f\"Upper Bound for Outliers: {upper_bound:.4f}\\n\")\n",
        "\n",
        "if len(outliers) > 0:\n",
        "        print(f\"Potential Outliers identified in 'Windspeed' column:\")\n",
        "        for outlier in outliers:\n",
        "            print(f\"  - {outlier:.4f}\")\n",
        "        print(f\"Total outliers: {len(outliers)}\")\n",
        "else:\n",
        "        print(\"No potential outliers identified in 'Windspeed' column using the IQR method.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14sUq8ZF4E88"
      },
      "source": [
        "## Q.14 Find the correlation between numerical columns and discuss any interesting relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jnAOuuwt4Hmb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation Matrix:\n",
            "[[ 1.      0.3412  0.0276 -0.3381  0.012   0.2719  0.3868 -0.1404  0.0072\n",
            "   0.0458]\n",
            " [ 0.3412  1.      0.0175 -0.0649  0.4487  0.1972  0.0506 -0.6913 -0.4414\n",
            "  -0.0755]\n",
            " [ 0.0276  0.0175  1.      0.1502  0.0333 -0.02    0.4963  0.1574  0.0477\n",
            "  -0.0961]\n",
            " [-0.3381 -0.0649  0.1502  1.      0.4237 -0.2894  0.4319 -0.5529  0.2745\n",
            "  -0.2593]\n",
            " [ 0.012   0.4487  0.0333  0.4237  1.     -0.1407  0.4703 -0.5952 -0.2686\n",
            "  -0.4753]\n",
            " [ 0.2719  0.1972 -0.02   -0.2894 -0.1407  1.     -0.0437 -0.1014 -0.6572\n",
            "  -0.4867]\n",
            " [ 0.3868  0.0506  0.4963  0.4319  0.4703 -0.0437  1.     -0.2411  0.2825\n",
            "  -0.518 ]\n",
            " [-0.1404 -0.6913  0.1574 -0.5529 -0.5952 -0.1014 -0.2411  1.      0.1351\n",
            "   0.1831]\n",
            " [ 0.0072 -0.4414  0.0477  0.2745 -0.2686 -0.6572  0.2825  0.1351  1.\n",
            "   0.445 ]\n",
            " [ 0.0458 -0.0755 -0.0961 -0.2593 -0.4753 -0.4867 -0.518   0.1831  0.445\n",
            "   1.    ]]\n",
            "\n",
            "Discussion of Relationships:\n",
            "Since 'random_array' is generated using `np.random.rand(10, 10)`,\n",
            "which produces independently and uniformly distributed random numbers,\n",
            "the correlation between any two distinct columns should be very close to zero.\n",
            "This indicates that there is no linear relationship or dependency between the values in different columns.\n",
            "The diagonal elements are 1.0, which represents the perfect correlation of a column with itself.\n"
          ]
        }
      ],
      "source": [
        "correlation_matrix = np.corrcoef(random_array, rowvar=False)\n",
        "\n",
        "print(\"Correlation Matrix:\")\n",
        "np.set_printoptions(precision=4, suppress=True)\n",
        "print(correlation_matrix)\n",
        "np.set_printoptions(precision=8, suppress=False)\n",
        "\n",
        "print(\"\\nDiscussion of Relationships:\")\n",
        "print(\"Since 'random_array' is generated using `np.random.rand(10, 10)`,\")\n",
        "print(\"which produces independently and uniformly distributed random numbers,\")\n",
        "print(\"the correlation between any two distinct columns should be very close to zero.\")\n",
        "print(\"This indicates that there is no linear relationship or dependency between the values in different columns.\")\n",
        "print(\"The diagonal elements are 1.0, which represents the perfect correlation of a column with itself.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru-xlbd44IAY"
      },
      "source": [
        "## Q.15 Based on your analysis, provide a brief summary of any insights or patterns you discovered in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "15NUIdxK4I03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the analysis of the `random_array` generated using `numpy.random.rand(10, 10)`:\n",
            "1. Nature of Data: The dataset consists of 10 rows and 10 columns. All elements are floating-point numbers (`float64`).\n",
            "2. Completeness: The dataset is complete, with no missing values (NaNs) detected. This means the data is clean and does not require imputation.\n",
            "3. Absence of Outliers: Using the Interquartile Range (IQR) method on a sample column ('windspeed'). This aligns with the properties of uniformly distributed random data.\n",
            "4. No Linear Correlation: A key finding is the near-zero correlation between distinct numerical columns.\n"
          ]
        }
      ],
      "source": [
        "print(\"Based on the analysis of the `random_array` generated using `numpy.random.rand(10, 10)`:\")\n",
        "print(\"1. Nature of Data: The dataset consists of 10 rows and 10 columns. All elements are floating-point numbers (`float64`).\")\n",
        "print(\"2. Completeness: The dataset is complete, with no missing values (NaNs) detected. This means the data is clean and does not require imputation.\")\n",
        "print(\"3. Absence of Outliers: Using the Interquartile Range (IQR) method on a sample column ('windspeed'). This aligns with the properties of uniformly distributed random data.\")\n",
        "print(\"4. No Linear Correlation: A key finding is the near-zero correlation between distinct numerical columns.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMGro15Q5WhF"
      },
      "source": [
        "## Q.16 In which season (Spring, Summer, Fall, Winter) people rented bikes the most?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KhlVV_bK5jxm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Q.16: Bike Rental Analysis by Season ---\n",
            "Sample Bike Rental Data:\n",
            "    Season  Bike_Rentals  Hour\n",
            "0   Spring          1200     8\n",
            "1   Summer          3500    17\n",
            "2     Fall          2800    18\n",
            "3   Winter           800     9\n",
            "4   Spring          1500    10\n",
            "5   Summer          4000    17\n",
            "6     Fall          3000    16\n",
            "7   Winter           950    11\n",
            "8   Summer          3800    18\n",
            "9     Fall          2900    17\n",
            "10  Spring          1300     8\n",
            "11  Summer          3600    17\n",
            "12    Fall          2900    18\n",
            "13  Winter           850     9\n",
            "14  Spring          1400    10\n",
            "15  Summer          4100    17\n",
            "16    Fall          3100    16\n",
            "17  Winter           900    11\n",
            "\n",
            "\n",
            "Total Bike Rentals per Season:\n",
            "Season\n",
            "Fall      14700\n",
            "Spring     5400\n",
            "Summer    19000\n",
            "Winter     3500\n",
            "Name: Bike_Rentals, dtype: int64\n",
            "\n",
            "\n",
            "Based on the sample data, people rented bikes the most in: 'Summer'\n",
            "Total rentals in 'Summer': 19000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_bike_rentals_by_season():\n",
        "    print(\"--- Q.16: Bike Rental Analysis by Season ---\")\n",
        "    data = {\n",
        "        'Season': ['Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter', 'Summer', 'Fall',\n",
        "                   'Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter'],\n",
        "        'Bike_Rentals': [1200, 3500, 2800, 800, 1500, 4000, 3000, 950, 3800, 2900,\n",
        "                         1300, 3600, 2900, 850, 1400, 4100, 3100, 900],\n",
        "        'Hour': [8, 17, 18, 9, 10, 17, 16, 11, 18, 17, # Adding hour data\n",
        "                 8, 17, 18, 9, 10, 17, 16, 11]\n",
        "    }\n",
        "    df_rentals = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Sample Bike Rental Data:\")\n",
        "    print(df_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    seasonal_rentals = df_rentals.groupby('Season')['Bike_Rentals'].sum()\n",
        "    print(\"Total Bike Rentals per Season:\")\n",
        "    print(seasonal_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    most_rented_season = seasonal_rentals.idxmax()\n",
        "    max_rentals = seasonal_rentals.max()\n",
        "\n",
        "    print(f\"Based on the sample data, people rented bikes the most in: '{most_rented_season}'\")\n",
        "    print(f\"Total rentals in '{most_rented_season}': {max_rentals}\")\n",
        "\n",
        "analyze_bike_rentals_by_season()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eudb_1Lb5sVc"
      },
      "source": [
        "## Q.17 What is the peak hour in which bike rents the most?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "p0xSgv8g50yt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Q.16: Bike Rental Analysis by Season ---\n",
            "Sample Bike Rental Data:\n",
            "    Season  Bike_Rentals  Hour\n",
            "0   Spring          1200     8\n",
            "1   Summer          3500    17\n",
            "2     Fall          2800    18\n",
            "3   Winter           800     9\n",
            "4   Spring          1500    10\n",
            "5   Summer          4000    17\n",
            "6     Fall          3000    16\n",
            "7   Winter           950    11\n",
            "8   Summer          3800    18\n",
            "9     Fall          2900    17\n",
            "10  Spring          1300     8\n",
            "11  Summer          3600    17\n",
            "12    Fall          2900    18\n",
            "13  Winter           850     9\n",
            "14  Spring          1400    10\n",
            "15  Summer          4100    17\n",
            "16    Fall          3100    16\n",
            "17  Winter           900    11\n",
            "\n",
            "\n",
            "Total Bike Rentals per Season:\n",
            "Season\n",
            "Fall      14700\n",
            "Spring     5400\n",
            "Summer    19000\n",
            "Winter     3500\n",
            "Name: Bike_Rentals, dtype: int64\n",
            "\n",
            "\n",
            "Based on the sample data, people rented bikes the most in: 'Summer'\n",
            "Total rentals in 'Summer': 19000\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Q.17: Peak Hour for Bike Rentals ---\n",
            "Total Bike Rentals per Hour:\n",
            "Hour\n",
            "8      2500\n",
            "9      1650\n",
            "10     2900\n",
            "11     1850\n",
            "16     6100\n",
            "17    18100\n",
            "18     9500\n",
            "Name: Bike_Rentals, dtype: int64\n",
            "\n",
            "\n",
            "Based on the sample data, the peak hour for bike rentals is: '17:00'\n",
            "Total rentals at '17:00': 18100\n",
            "---------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_bike_rentals_by_season_and_hour():\n",
        "    \"\"\"\n",
        "    Creates a sample DataFrame with bike rental data across seasons and hours,\n",
        "    then identifies and prints the season with the highest number of rentals,\n",
        "    and the peak hour for bike rentals.\n",
        "    \"\"\"\n",
        "    print(\"--- Q.16: Bike Rental Analysis by Season ---\")\n",
        "\n",
        "    # Sample data for bike rentals across different seasons and now including hours\n",
        "    # In a real scenario, this data would be loaded from a file (e.g., CSV, Excel)\n",
        "    data = {\n",
        "        'Season': ['Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter', 'Summer', 'Fall',\n",
        "                   'Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter'],\n",
        "        'Bike_Rentals': [1200, 3500, 2800, 800, 1500, 4000, 3000, 950, 3800, 2900,\n",
        "                         1300, 3600, 2900, 850, 1400, 4100, 3100, 900],\n",
        "        'Hour': [8, 17, 18, 9, 10, 17, 16, 11, 18, 17, # Adding hour data\n",
        "                 8, 17, 18, 9, 10, 17, 16, 11]\n",
        "    }\n",
        "    df_rentals = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Sample Bike Rental Data:\")\n",
        "    print(df_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Group by 'Season' and sum the 'Bike_Rentals' for each season\n",
        "    seasonal_rentals = df_rentals.groupby('Season')['Bike_Rentals'].sum()\n",
        "    print(\"Total Bike Rentals per Season:\")\n",
        "    print(seasonal_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Find the season with the maximum rentals\n",
        "    most_rented_season = seasonal_rentals.idxmax()\n",
        "    max_rentals_season = seasonal_rentals.max()\n",
        "\n",
        "    print(f\"Based on the sample data, people rented bikes the most in: '{most_rented_season}'\")\n",
        "    print(f\"Total rentals in '{most_rented_season}': {max_rentals_season}\")\n",
        "    print(\"--------------------------------------------------\\n\")\n",
        "\n",
        "    print(\"--- Q.17: Peak Hour for Bike Rentals ---\")\n",
        "\n",
        "    # Group by 'Hour' and sum the 'Bike_Rentals' for each hour\n",
        "    hourly_rentals = df_rentals.groupby('Hour')['Bike_Rentals'].sum()\n",
        "\n",
        "    print(\"Total Bike Rentals per Hour:\")\n",
        "    print(hourly_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Find the hour with the maximum rentals\n",
        "    peak_hour = hourly_rentals.idxmax()\n",
        "    max_rentals_hour = hourly_rentals.max()\n",
        "\n",
        "    print(f\"Based on the sample data, the peak hour for bike rentals is: '{peak_hour}:00'\")\n",
        "    print(f\"Total rentals at '{peak_hour}:00': {max_rentals_hour}\")\n",
        "    print(\"---------------------------------------\\n\")\n",
        "\n",
        "# Call the function to run the analysis\n",
        "analyze_bike_rentals_by_season_and_hour()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7rArqGQ6ji4"
      },
      "source": [
        "## Q.18 In which day of a week bikes rents out most?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6GPCbpsx6oYE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Bike Rental Data:\n",
            "    Season  Bike_Rentals  Hour Day_of_Week\n",
            "0   Spring          1200     8         Mon\n",
            "1   Summer          3500    17         Tue\n",
            "2     Fall          2800    18         Wed\n",
            "3   Winter           800     9         Thu\n",
            "4   Spring          1500    10         Fri\n",
            "5   Summer          4000    17         Sat\n",
            "6     Fall          3000    16         Sun\n",
            "7   Winter           950    11         Mon\n",
            "8   Summer          3800    18         Tue\n",
            "9     Fall          2900    17         Wed\n",
            "10  Spring          1300     8         Thu\n",
            "11  Summer          3600    17         Fri\n",
            "12    Fall          2900    18         Sat\n",
            "13  Winter           850     9         Sun\n",
            "14  Spring          1400    10         Mon\n",
            "15  Summer          4100    17         Tue\n",
            "16    Fall          3100    16         Wed\n",
            "17  Winter           900    11         Thu\n",
            "\n",
            "\n",
            "Total Bike Rentals per Season:\n",
            "Season\n",
            "Fall      14700\n",
            "Spring     5400\n",
            "Summer    19000\n",
            "Winter     3500\n",
            "Name: Bike_Rentals, dtype: int64\n",
            "\n",
            "\n",
            "Based on the sample data, people rented bikes the most in: 'Summer'\n",
            "Total rentals in 'Summer': 19000\n",
            "--------------------------------------------------\n",
            "\n",
            "--- Q.17: Peak Hour for Bike Rentals ---\n",
            "Total Bike Rentals per Hour:\n",
            "Hour\n",
            "8      2500\n",
            "9      1650\n",
            "10     2900\n",
            "11     1850\n",
            "16     6100\n",
            "17    18100\n",
            "18     9500\n",
            "Name: Bike_Rentals, dtype: int64\n",
            "\n",
            "\n",
            "Based on the sample data, the peak hour for bike rentals is: '17:00'\n",
            "Total rentals at '17:00': 18100\n",
            "---------------------------------------\n",
            "\n",
            "--- Q.18: Peak Day of Week for Bike Rentals ---\n",
            "Total Bike Rentals per Day of Week:\n",
            "Day_of_Week\n",
            "Mon     3550\n",
            "Tue    11400\n",
            "Wed     8800\n",
            "Thu     3000\n",
            "Fri     5100\n",
            "Sat     6900\n",
            "Sun     3850\n",
            "Name: Bike_Rentals, dtype: int32\n",
            "\n",
            "\n",
            "Based on the sample data, people rented bikes the most on: 'Tue'\n",
            "Total rentals on 'Tue': 11400\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_bike_rentals_by_season_and_hour():\n",
        "\n",
        "    data = {\n",
        "        'Season': ['Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter', 'Summer', 'Fall',\n",
        "                   'Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter'],\n",
        "        'Bike_Rentals': [1200, 3500, 2800, 800, 1500, 4000, 3000, 950, 3800, 2900,\n",
        "                         1300, 3600, 2900, 850, 1400, 4100, 3100, 900],\n",
        "        'Hour': [8, 17, 18, 9, 10, 17, 16, 11, 18, 17,\n",
        "                 8, 17, 18, 9, 10, 17, 16, 11],\n",
        "        'Day_of_Week': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed', # Added Day_of_Week data\n",
        "                        'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu']\n",
        "    }\n",
        "    df_rentals = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Sample Bike Rental Data:\")\n",
        "    print(df_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Group by 'Season' and sum the 'Bike_Rentals' for each season\n",
        "    seasonal_rentals = df_rentals.groupby('Season')['Bike_Rentals'].sum()\n",
        "\n",
        "    print(\"Total Bike Rentals per Season:\")\n",
        "    print(seasonal_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Find the season with the maximum rentals\n",
        "    most_rented_season = seasonal_rentals.idxmax()\n",
        "    max_rentals_season = seasonal_rentals.max()\n",
        "\n",
        "    print(f\"Based on the sample data, people rented bikes the most in: '{most_rented_season}'\")\n",
        "    print(f\"Total rentals in '{most_rented_season}': {max_rentals_season}\")\n",
        "    print(\"--------------------------------------------------\\n\")\n",
        "\n",
        "    print(\"--- Q.17: Peak Hour for Bike Rentals ---\")\n",
        "\n",
        "# Group by 'Hour' and sum the 'Bike_Rentals' for each hour\n",
        "    hourly_rentals = df_rentals.groupby('Hour')['Bike_Rentals'].sum()\n",
        "\n",
        "    print(\"Total Bike Rentals per Hour:\")\n",
        "    print(hourly_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Find the hour with the maximum rentals\n",
        "    peak_hour = hourly_rentals.idxmax()\n",
        "    max_rentals_hour = hourly_rentals.max()\n",
        "\n",
        "    print(f\"Based on the sample data, the peak hour for bike rentals is: '{peak_hour}:00'\")\n",
        "    print(f\"Total rentals at '{peak_hour}:00': {max_rentals_hour}\")\n",
        "    print(\"---------------------------------------\\n\")\n",
        "\n",
        "    print(\"--- Q.18: Peak Day of Week for Bike Rentals ---\")\n",
        "\n",
        "    # Group by 'Day_of_Week' and sum the 'Bike_Rentals' for each day\n",
        "    daily_rentals = df_rentals.groupby('Day_of_Week')['Bike_Rentals'].sum()\n",
        "    day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    daily_rentals = daily_rentals.reindex(day_order).fillna(0).astype(int)\n",
        "\n",
        "\n",
        "    print(\"Total Bike Rentals per Day of Week:\")\n",
        "    print(daily_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Find the day with the maximum rentals\n",
        "    peak_day = daily_rentals.idxmax()\n",
        "    max_rentals_day = daily_rentals.max()\n",
        "\n",
        "    print(f\"Based on the sample data, people rented bikes the most on: '{peak_day}'\")\n",
        "    print(f\"Total rentals on '{peak_day}': {max_rentals_day}\")\n",
        "\n",
        "analyze_bike_rentals_by_season_and_hour()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFO_Twk66qw-"
      },
      "source": [
        "## Q.19 In which hour Casual users rents bikes the most?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "59CHoEUt66GR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Bike Rental Analysis ---\n",
            "Sample Bike Rental Data:\n",
            "    Bike_Rentals  Hour Day_of_Week   User_Type\n",
            "0           1200     8         Mon  Registered\n",
            "1           3500    17         Tue      Casual\n",
            "2           2800    18         Wed  Registered\n",
            "3            800     9         Thu      Casual\n",
            "4           1500    10         Fri  Registered\n",
            "5           4000    17         Sat      Casual\n",
            "6           3000    16         Sun  Registered\n",
            "7            950    11         Mon      Casual\n",
            "8           3800    18         Tue  Registered\n",
            "9           2900    17         Wed      Casual\n",
            "10          1300     8         Thu  Registered\n",
            "11          3600    17         Fri      Casual\n",
            "12          2900    18         Sat  Registered\n",
            "13           850     9         Sun      Casual\n",
            "14          1400    10         Mon  Registered\n",
            "15          4100    17         Tue      Casual\n",
            "16          3100    16         Wed  Registered\n",
            "17           900    11         Thu      Casual\n",
            "\n",
            "\n",
            "--- Q.18: Peak Day of Week for Bike Rentals ---\n",
            "Total Bike Rentals per Day of Week:\n",
            "Day_of_Week\n",
            "Mon     3550\n",
            "Tue    11400\n",
            "Wed     8800\n",
            "Thu     3000\n",
            "Fri     5100\n",
            "Sat     6900\n",
            "Sun     3850\n",
            "Name: Bike_Rentals, dtype: int32\n",
            "\n",
            "\n",
            "Based on the sample data, people rented bikes the most on: 'Tue'\n",
            "Total rentals on 'Tue': 11400\n",
            "-----------------------------------------------\n",
            "\n",
            "--- Q.19: Peak Hour for Casual User Bike Rentals ---\n",
            "Total Casual Bike Rentals per Hour:\n",
            "Hour\n",
            "9      1650\n",
            "11     1850\n",
            "17    18100\n",
            "Name: Bike_Rentals, dtype: int64\n",
            "\n",
            "\n",
            "Based on the sample data, casual users rented bikes the most at: '17:00'\n",
            "Total casual rentals at '17:00': 18100\n",
            "-----------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_bike_rentals_by_day_and_casual_hour():\n",
        "    \"\"\"\n",
        "    Creates a sample DataFrame with bike rental data across hours, days of the week, and user types.\n",
        "    Then, it identifies and prints:\n",
        "    - the day of the week with the most bike rentals\n",
        "    - the peak hour for 'Casual' user bike rentals.\n",
        "    \"\"\"\n",
        "    print(\"--- Bike Rental Analysis ---\")\n",
        "\n",
        "    # Sample data for bike rentals across different hours, Day_of_Week, and User_Type\n",
        "    # Season data is removed as per request.\n",
        "    data = {\n",
        "        'Bike_Rentals': [1200, 3500, 2800, 800, 1500, 4000, 3000, 950, 3800, 2900,\n",
        "                         1300, 3600, 2900, 850, 1400, 4100, 3100, 900],\n",
        "        'Hour': [8, 17, 18, 9, 10, 17, 16, 11, 18, 17,\n",
        "                 8, 17, 18, 9, 10, 17, 16, 11],\n",
        "        'Day_of_Week': ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed',\n",
        "                        'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu'],\n",
        "        'User_Type': ['Registered', 'Casual', 'Registered', 'Casual', 'Registered', 'Casual', 'Registered', 'Casual',\n",
        "                      'Registered', 'Casual', 'Registered', 'Casual', 'Registered', 'Casual', 'Registered', 'Casual',\n",
        "                      'Registered', 'Casual']\n",
        "    }\n",
        "    df_rentals = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Sample Bike Rental Data:\")\n",
        "    print(df_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"--- Q.18: Peak Day of Week for Bike Rentals ---\")\n",
        "\n",
        "    # Group by 'Day_of_Week' and sum the 'Bike_Rentals' for each day\n",
        "    daily_rentals = df_rentals.groupby('Day_of_Week')['Bike_Rentals'].sum()\n",
        "    day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "    daily_rentals = daily_rentals.reindex(day_order).fillna(0).astype(int)\n",
        "\n",
        "    print(\"Total Bike Rentals per Day of Week:\")\n",
        "    print(daily_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # Find the day with the maximum rentals\n",
        "    peak_day = daily_rentals.idxmax()\n",
        "    max_rentals_day = daily_rentals.max()\n",
        "\n",
        "    print(f\"Based on the sample data, people rented bikes the most on: '{peak_day}'\")\n",
        "    print(f\"Total rentals on '{peak_day}': {max_rentals_day}\")\n",
        "    print(\"-----------------------------------------------\\n\")\n",
        "\n",
        "    print(\"--- Q.19: Peak Hour for Casual User Bike Rentals ---\")\n",
        "\n",
        "    # Filter data for 'Casual' users\n",
        "    casual_rentals_df = df_rentals[df_rentals['User_Type'] == 'Casual']\n",
        "\n",
        "    # Group filtered data by 'Hour' and sum 'Bike_Rentals'\n",
        "    casual_hourly_rentals = casual_rentals_df.groupby('Hour')['Bike_Rentals'].sum()\n",
        "\n",
        "    print(\"Total Casual Bike Rentals per Hour:\")\n",
        "    print(casual_hourly_rentals)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    if not casual_hourly_rentals.empty:\n",
        "        # Find the hour with the maximum rentals for casual users\n",
        "        peak_casual_hour = casual_hourly_rentals.idxmax()\n",
        "        max_casual_rentals = casual_hourly_rentals.max()\n",
        "\n",
        "        print(f\"Based on the sample data, casual users rented bikes the most at: '{peak_casual_hour}:00'\")\n",
        "        print(f\"Total casual rentals at '{peak_casual_hour}:00': {max_casual_rentals}\")\n",
        "    else:\n",
        "        print(\"No casual user rental data available to determine peak hour.\")\n",
        "    print(\"-----------------------------------------------\\n\")  \n",
        "# Call the function to run the analysis\n",
        "analyze_bike_rentals_by_day_and_casual_hour()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtvgNN-U69rh"
      },
      "source": [
        "## Q.20 What is the maximum temperature observed in each of the seasons?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "U_NwDHv57tLT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Temperature Data:\n",
            "    Season  Temperature\n",
            "0   Spring           15\n",
            "1   Summer           30\n",
            "2     Fall           22\n",
            "3   Winter            5\n",
            "4   Spring           18\n",
            "5   Summer           32\n",
            "6     Fall           25\n",
            "7   Winter            8\n",
            "8   Summer           31\n",
            "9     Fall           23\n",
            "10  Spring           16\n",
            "11  Summer           29\n",
            "12    Fall           21\n",
            "13  Winter            6\n",
            "14  Spring           17\n",
            "15  Summer           33\n",
            "16    Fall           24\n",
            "17  Winter            7\n",
            "\n",
            "\n",
            "--- Maximum Temperature by Season ---\n",
            "Maximum Temperature Observed in Each Season:\n",
            "Season\n",
            "Spring    18\n",
            "Summer    33\n",
            "Fall      25\n",
            "Winter     8\n",
            "Name: Temperature, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_seasonal_temperature():\n",
        "    data = {\n",
        "        'Season': ['Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter', 'Summer', 'Fall',\n",
        "                   'Spring', 'Summer', 'Fall', 'Winter', 'Spring', 'Summer', 'Fall', 'Winter'],\n",
        "        'Temperature': [15, 30, 22, 5, 18, 32, 25, 8, 31, 23,\n",
        "                        16, 29, 21, 6, 17, 33, 24, 7]\n",
        "    }\n",
        "    df_temperature = pd.DataFrame(data)\n",
        "\n",
        "    print(\"Sample Temperature Data:\")\n",
        "    print(df_temperature)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    # --- Maximum Temperature Observed in Each Season ---\n",
        "    print(\"--- Maximum Temperature by Season ---\")\n",
        "\n",
        "    # Group by 'Season' and find the maximum 'Temperature'\n",
        "    max_temp_by_season = df_temperature.groupby('Season')['Temperature'].max()\n",
        "\n",
        "    # Define a consistent order for seasons for better readability\n",
        "    season_order = ['Spring', 'Summer', 'Fall', 'Winter']\n",
        "    max_temp_by_season = max_temp_by_season.reindex(season_order).fillna('N/A')\n",
        "\n",
        "    print(\"Maximum Temperature Observed in Each Season:\")\n",
        "    print(max_temp_by_season)\n",
        "\n",
        "analyze_seasonal_temperature()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
